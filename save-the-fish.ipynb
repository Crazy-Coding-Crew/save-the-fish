{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fischer's Fritz fischt frische Fische"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with defining a helper function to display multiple images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "def show_plots(N, imgs, fig_title=\"\",sub_titles=[]):\n",
    "    \"\"\"\n",
    "    N     ... number of plots to show (should be < len(img))\n",
    "    img   ... list of images as numpy 3D arrays (for RGB)\n",
    "    title ... optional title\n",
    "    \"\"\"\n",
    "    if not len(sub_titles):\n",
    "        sub_titles = [\"\"] * len(imgs)\n",
    "    rows = (N + 3) // 4 \n",
    "    select_index = np.random.choice(len(imgs),size = min(N,len(imgs)))\n",
    "    select_imgs = [imgs[i] for i in select_index]\n",
    "    select_titles = [sub_titles[i] for i in select_index]\n",
    "    _, ax = plt.subplots(rows, 4, sharex='col', sharey='row', figsize=(20, 3 * rows))\n",
    "    if fig_title:\n",
    "        plt.suptitle(fig_title, y = 0.98 + .1/rows, size=20)\n",
    "    for i, (img, title) in enumerate(zip(select_imgs,select_titles)):\n",
    "        a = ax[i] if len(ax.shape) < 2 else ax[i // 4, i % 4]\n",
    "        a.imshow(img)\n",
    "        if title:\n",
    "            a.set_title(title)\n",
    "        a.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to load the training data. First, get a list of all image file names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "training_filenames = glob.glob('train/*/*.jpg')\n",
    "print('Found {} training images.'.format(len(training_filenames)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For future processing it may be useful to have unique identifiers for each image such that one can easily associated training and classification information (e.g. boat type, day/night etc, predicted category). We could use a database here, but let's keep it simple for the moment. We are going to use `pandas.DataFrame` with a MD5 hash of the filename as index. In addition to the filename itself, we will already store the true label (i.e. the fish species).  \n",
    "In order to save time in future iterations, the data frame will be saved into a `pickle` file which can be loaded in subsequent runs. Make sure that you save the data frame if you added valueable information (e.g. output from clusterisation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def init_data_frame(pickle_file=\"df.pickle\"):\n",
    "    \"\"\"\n",
    "    load a pandas.DataFrame from given pickle file or initialise if file does not exist\n",
    "    \"\"\"\n",
    "    import hashlib, os, pickle, re\n",
    "    \n",
    "    # check for pickle file and load data frame if it exists\n",
    "    if os.path.isfile(pickle_file):\n",
    "        print(\"load from pickle file '{}'\".format(pickle_file))\n",
    "        df = pickle.load(open(pickle_file))\n",
    "        return df\n",
    "    \n",
    "    # no pickle file found -> create data frame\n",
    "    print('create pandas.DataFrame from scratch')\n",
    "    \n",
    "    # get MD5 hash of filename as index\n",
    "    index = [hashlib.md5(f).hexdigest() for f in training_filenames]\n",
    "\n",
    "    # extract true label from filename\n",
    "    label_pattern = re.compile('train/([^/]+)/img_.*jpg')\n",
    "    true_labels = [label_pattern.match(f).group(1)  for f in training_filenames]\n",
    "\n",
    "    # construct the dataframe\n",
    "    df = pd.DataFrame(data={'filename': training_filenames, 'true label': true_labels},index=index)\n",
    "    print(\"save data frame to '{}'\".format(pickle_file))\n",
    "    df.to_pickle(pickle_file)\n",
    "    return df\n",
    "\n",
    "df = init_data_frame()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's actually load some of the images. To avoid any bias, we pick the subset of training images randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imread\n",
    "import numpy as np\n",
    "n_images = 1000\n",
    "train_df = df.sample(n_images)\n",
    "train = np.array([imread(img) for img in train_df['filename']])\n",
    "print('Number of training images loaded {}.'.format(len(train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When performing image processing, it always is important to know the dimensions of the images. So let's have a look, what we've got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Image sizes in training sample:')\n",
    "shapes = np.array([str(img.shape) for img in train])\n",
    "pd.Series(shapes).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot some example images for each image size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for uniq in pd.Series(shapes).unique():\n",
    "    show_plots(4,train[shapes == uniq], 'Images with shape: {}'.format(uniq),train_df['filename'][shapes == uniq])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first pre-processing step, we may want to try to cluster images into categories where each category corresponds to one fishing cutter. This could potentially be useful for the following steps:\n",
    "* identify areas of the image which do not change (e.g. structure of the boat itself) and therefore limit the area where to look for the fish\n",
    "* build a different model for each boat (my assumption is that the prior distribution for each fish species depends on the fishing region, and thus, maybe on the boat as well)\n",
    "We will use `sklearn.DBSCAN` as clusterisation algorithm which requires as input the pair-wise distance matrix between all images. As a start, the distance between to images is defined as mean absolute pixel error after normalisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2, multiprocessing, progressbar\n",
    "\n",
    "# Function for computing distance between images\n",
    "def compare(args):\n",
    "    img, img2 = args\n",
    "    img = (img - img.mean()) / img.std()\n",
    "    img2 = (img2 - img2.mean()) / img2.std()\n",
    "    return np.mean(np.abs(img - img2))\n",
    "\n",
    "# Resize the images to speed it up.\n",
    "train_rescaled = [cv2.resize(img, dsize=(50, 50)) for img in train]\n",
    "\n",
    "# Create the distance matrix in a multithreaded fashion\n",
    "pool = multiprocessing.Pool(4)\n",
    "distances = np.zeros((len(train_rescaled), len(train_rescaled)))\n",
    "bar = progressbar.ProgressBar(maxval=len(train_rescaled))\n",
    "bar.start()\n",
    "for i, img in enumerate(train_rescaled):\n",
    "    bar.update(i+1)\n",
    "    all_imgs = [(img, f) for f in train_rescaled]\n",
    "    dists = pool.map(compare, all_imgs)\n",
    "    distances[i, :] = dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print distances.shape\n",
    "print len(distances.flatten())\n",
    "plt.hist(distances.flatten(), bins=50)\n",
    "plt.title('Histogram of distance matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import cluster\n",
    "cls = cluster.DBSCAN(metric='precomputed', min_samples=5, eps=0.6)\n",
    "y = cls.fit_predict(distances)\n",
    "print(y)\n",
    "print('Cluster sizes:')\n",
    "print(pd.Series(y).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for uniq in pd.Series(y).value_counts().index:\n",
    "    if uniq != -1:\n",
    "        size = len(np.array(train_rescaled)[y == uniq])\n",
    "        if size > 12:\n",
    "            show_plots(12,np.array(train_rescaled)[y == uniq], 'BoatID: {} - Image count {}'.format(uniq, size))\n",
    "            plt.show()\n",
    "        else:\n",
    "            show_plots(size,np.array(train_rescaled)[y == uniq], 'BoatID: {} - Image count {}'.format(uniq, size))\n",
    "            plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size = len(np.array(train)[y == -1])\n",
    "show_plots(size,np.array(train)[y == -1], 'BoatID: {} (Unclassified images) - Image count {}'.format(-1, size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "same = distances[y == 15][:,y==15]\n",
    "plt.imshow(same,interpolation='none')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print np.arange(500)[y==28]\n",
    "print np.arange(500)[y==15]\n",
    "print distances[np.arange(500)[y==15],433]\n",
    "show_plots(1,[train_rescaled[335]],\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask = [e in [15,28] for e in y]\n",
    "similar = [img for (img,m) in zip(train_rescaled,mask) if m]\n",
    "show_plots(len(similar),similar,\"same boat but different categories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import feature, color\n",
    "img1 = color.rgb2gray(train_rescaled[335])\n",
    "img2 = color.rgb2gray(train_rescaled[433])\n",
    "edges1 = feature.canny(img1, sigma=2)\n",
    "edges2 = feature.canny(img2, sigma=2)\n",
    "_, ax = plt.subplots(nrows=2, ncols=2, figsize=(20, 6), sharex=True, sharey=True)\n",
    "for i,im in enumerate([img1,edges1,img2,edges2]):\n",
    "    a = ax[i // 2, i % 2]\n",
    "    a.imshow(im,cmap='gray')\n",
    "    a.axis('off')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
